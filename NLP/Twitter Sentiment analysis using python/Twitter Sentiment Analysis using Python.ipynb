{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f7c468-55fc-49e7-8a25-364345d29428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhanya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Install Necessary Libraries\n",
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d33062d-ceb1-43d0-8513-9d36353de6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915835c8-1dce-4947-ad3a-21acb51c9c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   polarity                                               text\n",
      "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1         0  is upset that he can't update his Facebook by ...\n",
      "2         0  @Kenichan I dived many times for the ball. Man...\n",
      "3         0    my whole body feels itchy and like its on fire \n",
      "4         0  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)\n",
    "df = df[[0, 5]]\n",
    "df.columns = ['polarity', 'text']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9737ac78-4b20-4ead-a310-6d8e9f90e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Keep Only Positive and Negative Sentiments\n",
    "df = df[df.polarity != 2]\n",
    "\n",
    "df['polarity'] = df['polarity'].map({0: 0, 4: 1})\n",
    "\n",
    "print(df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fcc7718-5a47-4dda-9bb3-5009462d595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1  is upset that he can't update his Facebook by ...   \n",
      "2  @Kenichan I dived many times for the ball. Man...   \n",
      "3    my whole body feels itchy and like its on fire    \n",
      "4  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                                          clean_text  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
      "1  is upset that he can't update his facebook by ...  \n",
      "2  @kenichan i dived many times for the ball. man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "#Clean the Tweets\n",
    "def clean_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "print(df[['text', 'clean_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b249d66-1780-4028-aecb-76063d19ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1280000\n",
      "Test size: 320000\n"
     ]
    }
   ],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_text'],\n",
    "    df['polarity'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1fdfb0-228c-42b7-9a89-1b6a433edd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape (train): (1280000, 5000)\n",
      "TF-IDF shape (test): (320000, 5000)\n"
     ]
    }
   ],
   "source": [
    "#Perform Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF shape (train):\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF shape (test):\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883e0d3d-e7ac-4585-91cd-ce2c9c56edce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy: 0.766490625\n",
      "\n",
      "BernoulliNB Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76    159494\n",
      "           1       0.76      0.78      0.77    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Bernoulli Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "bnb_pred = bnb.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(y_test, bnb_pred))\n",
    "print(\"\\nBernoulliNB Classification Report:\\n\", classification_report(y_test, bnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d214b088-f229-4b97-bf4a-9433e3572430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.79531875\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    159494\n",
      "           1       0.79      0.81      0.80    160506\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Support Vector Machine (SVM) model\n",
    "svm = LinearSVC(max_iter=1000)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "svm_pred = svm.predict(X_test_tfidf)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f84ffd9-e233-481b-8035-8763bea137ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.796084375\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    159494\n",
      "           1       0.79      0.81      0.80    160506\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=100)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "logreg_pred = logreg.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb7b02c0-f1f5-45d5-9a40-4ddf65725f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "BernoulliNB: [1 0 1]\n",
      "SVM: [1 0 1]\n",
      "Logistic Regression: [1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Make Predictions on sample Tweets\n",
    "sample_tweets = [\"I love this!\", \"I hate that!\", \"It was okay, not great.\"]\n",
    "sample_vec = vectorizer.transform(sample_tweets)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(\"BernoulliNB:\", bnb.predict(sample_vec))\n",
    "print(\"SVM:\", svm.predict(sample_vec))\n",
    "print(\"Logistic Regression:\", logreg.predict(sample_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd1ec7-b6f4-4c5c-9889-76bf07979e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f545358-8a31-4e42-b16d-c0be29a14e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
